{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = 'https://www.nfl.com'\n",
    "teamAbbr = pd.Series([\"SF\",\"CHI\",\"CIN\",\"BUF\",\"DEN\",\"CLE\",\"TB\",\"ARI\",\"LAC\",\"KC\",\"IND\",\"DAL\",\"MIA\",\"PHI\",\"ATL\",\"NYG\",\n",
    "                     \"JAX\",\"NYJ\",\"DET\",\"GB\",\"CAR\",\"NE\",\"OAK\",\"LAR\",\"BAL\",\"WAS\",\"NO\",\"SEA\",\"PIT\",\"HOU\",\"TEN\",\"MIN\"])\n",
    "teamLocation = pd.Series([\"San Francisco\",\"Chicago\",\"Cincinatti\",\"Buffalo\",\"Denver\",\"Cleveland\",\"Tampa Bay\",\"Arizona\",\n",
    "                         \"Los Angeles\",\"Kansas City\",\"Indianapolis\",\"Dallas\",\"Miami\",\"Philadelphia\",\"Atlanta\",\"New York\",\n",
    "                         \"Jacksonville\",\"New York\",\"Detroit\",\"Green Bay\",\"Carolina\",\"New England\",\"Oakland\",\"Los Angeles\",\n",
    "                         \"Baltimore\",\"Washington\",\"New Orleans\",\"Seattle\",\"Pittsburgh\",\"Houston\",\"Tennessee\",\"Minnesota\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "playerPayload = {\"type\":\"/stats\",\"subject\":\"player-stats\",\"category\":\"category\",\n",
    "                 \"statisticCategory\":\"rushing\",\"season\":\"2019\",\n",
    "                 \"seasonType\":\"REG\",\n",
    "                 \"list\":\"all\",\n",
    "                 \"specificCategory\":\"rushingYards\",\n",
    "                 \"order\":\"DESC\"}\n",
    "\n",
    "teamPayload = {\"type\":\"/stats\",\"subject\":\"team-stats\",\"category\":\"offense\",\n",
    "               \"statisticCategory\":\"passing\",\n",
    "               \"season\":\"2019\",\n",
    "               \"seasonType\":\"REG\",\n",
    "               \"list\":\"all\",\n",
    "               \"specificCategory\":\"\",\n",
    "               \"order\":\"\"}\n",
    "\n",
    "schedulePayload = {\"type\":\"/schedules\",\n",
    "                  \"season\":\"2019\",\n",
    "                  \"seasonType\":\"REG\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = schedulePayload\n",
    "\n",
    "url = 'https://www.nfl.com'\n",
    "for key in payload:\n",
    "    if payload[key]:\n",
    "        url += payload[key]\n",
    "        url += '/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/schedules/2019/REG1/\n",
      "Response: 200 https://www.nfl.com/schedules/2019/PRE0/\n",
      "Response: 200 https://www.nfl.com/schedules/2019/PRE1/\n",
      "Response: 200 https://www.nfl.com/schedules/2019/PRE2/\n",
      "Response: 200 https://www.nfl.com/schedules/2019/PRE3/\n",
      "Response: 200 https://www.nfl.com/schedules/2019/PRE4/\n",
      "Response: 200 https://www.nfl.com/schedules/2019/REG1/\n",
      "Response: 200 https://www.nfl.com/schedules/2019/REG2/\n",
      "Response: 200 https://www.nfl.com/schedules/2019/REG3/\n",
      "Response: 200 https://www.nfl.com/schedules/2019/REG4/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-fd29f305cad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mseasonWeeks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mweek\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseasonWeeks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseUrl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mweek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Response:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "season = soup.find_all('select', {\"class\":\"d3-o-dropdown\"})[1].find_all(\"option\")\n",
    "seasonWeeks = []\n",
    "for week in season:\n",
    "    seasonWeeks.append(week.get(\"value\"))\n",
    "current = soup.find_all('select', {\"class\":\"d3-o-dropdown\"})[1].find('option', {\"selected\":True}).get(\"value\")\n",
    "print(current)\n",
    "seasonWeeks\n",
    "for week in seasonWeeks:\n",
    "    time.sleep(1)\n",
    "    response = requests.get(baseUrl+week)\n",
    "    print(\"Response:\", response.status_code,response.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://www.nfl.com/schedules/2019/REG/\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-87c6972dfd40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "tableRows = []\n",
    "pagingText = True\n",
    "\n",
    "\n",
    "while pagingText:\n",
    "    time.sleep(2)\n",
    "    response = requests.get(url)\n",
    "    print(\"url:\",response.url)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    table = soup.find('table')\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        if cols:\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            tableRows.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "    pagingText = soup.find(\"a\", {\"class\": \"nfl-o-table-pagination__next\"})\n",
    "    if pagingText:\n",
    "        url = baseUrl + pagingText.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDf = pd.DataFrame(tableRows, columns=columnHeader)\n",
    "# remove \\n whitespace from team names\n",
    "find = re.compile(r\"^(\\n*).*\")\n",
    "resultsDf['Team'] = resultsDf['Team'].apply(lambda x: re.search(find,x).group())\n",
    "pd.DataFrame.head(resultsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStats(url, payload): \n",
    "    tableRows = []\n",
    "    pagingText = True\n",
    "    \n",
    "    for key in payload:\n",
    "        if payload[key]:\n",
    "            url += payload[key]\n",
    "            url += '/'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # get column names\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    columnHeader = []\n",
    "    header = soup.find('table').find_all('th')\n",
    "    for col in header:\n",
    "        columnHeader.append(col.text)\n",
    "    columnHeader = [c.strip('\\n') for c in columnHeader]\n",
    "\n",
    "    # search through pages and append to tableRows\n",
    "    while pagingText:\n",
    "        time.sleep(2)\n",
    "        response = requests.get(url)\n",
    "        print(\"url:\",response.url)\n",
    "        soup = BeautifulSoup(response.text,'html.parser')\n",
    "        table = soup.find('table')\n",
    "        rows = table.find_all('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            if cols:\n",
    "                cols = [ele.text.strip() for ele in cols]\n",
    "                cols = [ele.rstrip('\\n') for ele in cols]\n",
    "                tableRows.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "        pagingText = soup.find(\"a\", {\"class\": \"nfl-o-table-pagination__next\"})\n",
    "        if pagingText:\n",
    "            url = baseUrl + pagingText.get('href')\n",
    "    \n",
    "    resultsDf = pd.DataFrame(tableRows, columns=columnHeader)\n",
    "    find = re.compile(r\"^(\\n*).*\")\n",
    "    resultsDf['Team'] = resultsDf['Team'].apply(lambda x: re.search(find,x).group())\n",
    "    \n",
    "    # add teamId to table\n",
    "    resultsDf = resultsDf.sort_values(by=['Team']).reset_index(drop=True)\n",
    "    resultsDf['teamId'] = teamAbbr\n",
    "    resultsDf['teamLoc'] = teamLocation\n",
    "    return resultsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://www.nfl.com/stats/team-stats/offense/passing/2019/reg/all\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Att</th>\n",
       "      <th>Cmp</th>\n",
       "      <th>Cmp %</th>\n",
       "      <th>Yds/Att</th>\n",
       "      <th>Pass Yds</th>\n",
       "      <th>TD</th>\n",
       "      <th>INT</th>\n",
       "      <th>Rate</th>\n",
       "      <th>1st</th>\n",
       "      <th>1st%</th>\n",
       "      <th>20+</th>\n",
       "      <th>40+</th>\n",
       "      <th>Lng</th>\n",
       "      <th>Sck</th>\n",
       "      <th>SckY</th>\n",
       "      <th>teamId</th>\n",
       "      <th>teamLoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49ers</td>\n",
       "      <td>478</td>\n",
       "      <td>331</td>\n",
       "      <td>69.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4029</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>103.1</td>\n",
       "      <td>195</td>\n",
       "      <td>40.8</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>75T</td>\n",
       "      <td>36</td>\n",
       "      <td>237</td>\n",
       "      <td>SF</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bears</td>\n",
       "      <td>580</td>\n",
       "      <td>371</td>\n",
       "      <td>64</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3573</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>83.9</td>\n",
       "      <td>178</td>\n",
       "      <td>30.7</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>282</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bengals</td>\n",
       "      <td>616</td>\n",
       "      <td>356</td>\n",
       "      <td>57.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3994</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>76.2</td>\n",
       "      <td>191</td>\n",
       "      <td>31</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>66T</td>\n",
       "      <td>48</td>\n",
       "      <td>342</td>\n",
       "      <td>CIN</td>\n",
       "      <td>Cincinatti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bills</td>\n",
       "      <td>513</td>\n",
       "      <td>299</td>\n",
       "      <td>58.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3476</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>82.8</td>\n",
       "      <td>162</td>\n",
       "      <td>31.6</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>53T</td>\n",
       "      <td>40</td>\n",
       "      <td>247</td>\n",
       "      <td>BUF</td>\n",
       "      <td>Buffalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Broncos</td>\n",
       "      <td>504</td>\n",
       "      <td>312</td>\n",
       "      <td>61.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3401</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>84.1</td>\n",
       "      <td>162</td>\n",
       "      <td>32.1</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>75T</td>\n",
       "      <td>41</td>\n",
       "      <td>286</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team  Att  Cmp Cmp % Yds/Att Pass Yds  TD INT   Rate  1st  1st% 20+ 40+  \\\n",
       "0    49ers  478  331  69.2     8.4     4029  28  13  103.1  195  40.8  62   8   \n",
       "1    Bears  580  371    64     6.2     3573  20  12   83.9  178  30.7  39   2   \n",
       "2  Bengals  616  356  57.8     6.5     3994  18  16   76.2  191    31  48   7   \n",
       "3    Bills  513  299  58.3     6.8     3476  21  12   82.8  162  31.6  54   8   \n",
       "4  Broncos  504  312  61.9     6.7     3401  16  10   84.1  162  32.1  46  10   \n",
       "\n",
       "   Lng Sck SckY teamId        teamLoc  \n",
       "0  75T  36  237     SF  San Francisco  \n",
       "1   53  45  282    CHI        Chicago  \n",
       "2  66T  48  342    CIN     Cincinatti  \n",
       "3  53T  40  247    BUF        Buffalo  \n",
       "4  75T  41  286    DEN         Denver  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teamPayload = {\"stats\":\"/stats\",\"subject\":\"team-stats\",\n",
    "               \"category\":\"offense\",\n",
    "               \"statisticCategory\":\"passing\",\n",
    "               \"season\":\"2019\",\n",
    "               \"seasonType\":\"REG\",\n",
    "               \"list\":\"all\",\n",
    "               \"specificCategory\":\"\",\n",
    "               \"order\":\"\"}\n",
    "df1 = getStats(baseUrl,teamPayload)\n",
    "pd.DataFrame.head(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamDf = df1[['teamId','teamLoc','Team']]\n",
    "pd.DataFrame.head(teamDf,20)\n",
    "\n",
    "teamsJson = teamDf.to_json(orient='records')\n",
    "\n",
    "with open(\"teams.json\",\"w\") as outfile:\n",
    "    outfile.write(teamsJson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatchups(url,payload):\n",
    "    for key in payload:\n",
    "        if payload[key]:\n",
    "            url += payload[key]\n",
    "            url += '/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    matchups = []\n",
    "    columnHeader = ['matchupId', 'team1', 'team2', 'team1Score','team2Score','weekType','weekNum']\n",
    "    season = soup.find_all('select', {\"class\":\"d3-o-dropdown\"})[1].find_all(\"option\")\n",
    "    seasonWeeks = []\n",
    "    for week in season:\n",
    "        seasonWeeks.append(week.get(\"value\"))\n",
    "    for week in seasonWeeks:\n",
    "        time.sleep(2)\n",
    "        url = baseUrl + week\n",
    "        response = requests.get(url)\n",
    "        print(url)\n",
    "        soup = BeautifulSoup(response.text,'html.parser')\n",
    "        weekName = week.rsplit('/', 2)[-2]\n",
    "        weekType = re.findall(\"[a-zA-Z]+\", weekName)[0]\n",
    "        weekNum = re.findall(r'\\d+', weekName)[0]\n",
    "        games = soup.find_all('a', {\"class\": \"nfl-c-matchup-strip__game\"})\n",
    "        index = 0\n",
    "        for game in games:\n",
    "            gameSoup = game.find_all('span', {\"class\":\"nfl-c-matchup-strip__team-abbreviation\"})\n",
    "            matchup = []\n",
    "            matchup.append(str(index))\n",
    "            for team in gameSoup:\n",
    "                matchup.append(re.sub(r'[^A-Za-z]', '', team.get_text()))\n",
    "            scoreSoup = game.find_all('div', {'class':\"nfl-c-matchup-strip__team-score\"})\n",
    "            if scoreSoup:\n",
    "                for team in scoreSoup:\n",
    "                    matchup.append(team.get_text())\n",
    "            else:\n",
    "                matchup.append(\"\")\n",
    "                matchup.append(\"\")\n",
    "            matchup.append(weekType)\n",
    "            matchup.append(weekNum)\n",
    "            matchups.append(matchup)\n",
    "            index += 1\n",
    "    matchupsDf = pd.DataFrame(matchups,columns=columnHeader)\n",
    "    return matchupsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.nfl.com/schedules/2019/PRE0/\n",
      "https://www.nfl.com/schedules/2019/PRE1/\n",
      "https://www.nfl.com/schedules/2019/PRE2/\n",
      "https://www.nfl.com/schedules/2019/PRE3/\n",
      "https://www.nfl.com/schedules/2019/PRE4/\n",
      "https://www.nfl.com/schedules/2019/REG1/\n",
      "https://www.nfl.com/schedules/2019/REG2/\n",
      "https://www.nfl.com/schedules/2019/REG3/\n",
      "https://www.nfl.com/schedules/2019/REG4/\n",
      "https://www.nfl.com/schedules/2019/REG5/\n",
      "https://www.nfl.com/schedules/2019/REG6/\n",
      "https://www.nfl.com/schedules/2019/REG7/\n",
      "https://www.nfl.com/schedules/2019/REG8/\n",
      "https://www.nfl.com/schedules/2019/REG9/\n",
      "https://www.nfl.com/schedules/2019/REG10/\n",
      "https://www.nfl.com/schedules/2019/REG11/\n",
      "https://www.nfl.com/schedules/2019/REG12/\n",
      "https://www.nfl.com/schedules/2019/REG13/\n",
      "https://www.nfl.com/schedules/2019/REG14/\n",
      "https://www.nfl.com/schedules/2019/REG15/\n",
      "https://www.nfl.com/schedules/2019/REG16/\n",
      "https://www.nfl.com/schedules/2019/REG17/\n",
      "https://www.nfl.com/schedules/2019/POST1/\n",
      "https://www.nfl.com/schedules/2019/POST2/\n",
      "https://www.nfl.com/schedules/2019/POST3/\n",
      "https://www.nfl.com/schedules/2019/PRO1/\n",
      "https://www.nfl.com/schedules/2019/POST4/\n"
     ]
    }
   ],
   "source": [
    "schedulePayload = {\"type\":\"/schedules\",\n",
    "                  \"season\":\"2019\",\n",
    "                  \"seasonType\":\"REG\"}\n",
    "df2 = getMatchups(baseUrl,schedulePayload)\n",
    "\n",
    "#matchupsDf.loc[(matchupsDf['weekType']=='REG') & (matchupsDf['weekNum']=='1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchupId</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>team1Score</th>\n",
       "      <th>team2Score</th>\n",
       "      <th>weekType</th>\n",
       "      <th>weekNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DEN</td>\n",
       "      <td>ATL</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>PRE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NYJ</td>\n",
       "      <td>NYG</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>PRE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>IND</td>\n",
       "      <td>BUF</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>PRE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>TEN</td>\n",
       "      <td>PHI</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>PRE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>ATL</td>\n",
       "      <td>MIA</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>PRE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>3</td>\n",
       "      <td>SEA</td>\n",
       "      <td>GB</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>POST</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0</td>\n",
       "      <td>TEN</td>\n",
       "      <td>KC</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>POST</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>SF</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>POST</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0</td>\n",
       "      <td>NFC</td>\n",
       "      <td>AFC</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>PRO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0</td>\n",
       "      <td>SF</td>\n",
       "      <td>KC</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>POST</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     matchupId team1 team2 team1Score team2Score weekType weekNum\n",
       "0            0   DEN   ATL         14         10      PRE       0\n",
       "1            0   NYJ   NYG         22         31      PRE       1\n",
       "2            1   IND   BUF         16         24      PRE       1\n",
       "3            2   TEN   PHI         27         10      PRE       1\n",
       "4            3   ATL   MIA         27         34      PRE       1\n",
       "..         ...   ...   ...        ...        ...      ...     ...\n",
       "328          3   SEA    GB         23         28     POST       2\n",
       "329          0   TEN    KC         24         35     POST       3\n",
       "330          1    GB    SF         20         37     POST       3\n",
       "331          0   NFC   AFC         33         38      PRO       1\n",
       "332          0    SF    KC         20         31     POST       4\n",
       "\n",
       "[333 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchupsJson = df2.to_json(orient='records')\n",
    "\n",
    "with open(\"matchups.json\",\"w\") as outfile:\n",
    "    outfile.write(matchupsJson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekTypeD = {\"PRE\":\"Pre-Season\", \"REG\":\"Regular Season\", \"POST\": \"Post-Season\"}\n",
    "\n",
    "\n",
    "def getWeeks(url,payload):\n",
    "    for key in payload:\n",
    "        if payload[key]:\n",
    "            url += payload[key]\n",
    "            url += '/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    columnHeader = ['weekType','weekNum','weekTypeF','weekF']\n",
    "    matchups = []\n",
    "    season = soup.find_all('select', {\"class\":\"d3-o-dropdown\"})[1].find_all(\"option\")\n",
    "    seasonWeeks = []\n",
    "    for week in season:\n",
    "        seasonWeeks.append(week.get(\"value\"))\n",
    "    for week in seasonWeeks:\n",
    "        url = baseUrl + week\n",
    "        weekName = week.rsplit('/', 2)[-2]\n",
    "        weekType = re.findall(\"[a-zA-Z]+\", weekName)[0]\n",
    "        weekNum = re.findall(r'\\d+', weekName)[0]\n",
    "        if weekType in weekTypeD.keys():\n",
    "            weekTypeF = weekTypeD[weekType]\n",
    "            weekF = weekTypeF + \" Week \" + weekNum\n",
    "            matchup = []\n",
    "            matchup.append(weekType)\n",
    "            matchup.append(weekNum)\n",
    "            matchup.append(weekTypeF)\n",
    "            matchup.append(weekF)\n",
    "            matchups.append(matchup)\n",
    "    weeksDf = pd.DataFrame(matchups,columns=columnHeader)\n",
    "    return weeksDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedulePayload = {\"type\":\"/schedules\",\n",
    "                  \"season\":\"2018\",\n",
    "                  \"seasonType\":\"REG\"}\n",
    "df3 = getWeeks(baseUrl,schedulePayload)\n",
    "df3\n",
    "weeksJson = df3.to_json(orient='records')\n",
    "\n",
    "with open(\"weeks.json\",\"w\") as outfile:\n",
    "    outfile.write(weeksJson)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
