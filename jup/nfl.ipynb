{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site used for scraping data\n",
    "baseUrl = 'https://www.nfl.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting stats off nfl.com/stats/\n",
    "def getStats(url, payload): \n",
    "    tableRows = []\n",
    "    pagingText = True\n",
    "    \n",
    "    for key in payload:\n",
    "        if payload[key]:\n",
    "            url += payload[key]\n",
    "            url += '/'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # get column names\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    columnHeader = []\n",
    "    header = soup.find('table').find_all('th')\n",
    "    for col in header:\n",
    "        columnHeader.append(col.text)\n",
    "    columnHeader = [c.strip('\\n') for c in columnHeader]\n",
    "\n",
    "    # search through pages and append to tableRows\n",
    "    while pagingText:\n",
    "        time.sleep(0.5)\n",
    "        response = requests.get(url)\n",
    "        print(\"url:\",response.url)\n",
    "        soup = BeautifulSoup(response.text,'html.parser')\n",
    "        table = soup.find('table')\n",
    "        rows = table.find_all('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            if cols:\n",
    "                cols = [ele.text.strip() for ele in cols]\n",
    "                cols = [ele.rstrip('\\n') for ele in cols]\n",
    "                tableRows.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "        pagingText = soup.find(\"a\", {\"class\": \"nfl-o-table-pagination__next\"})\n",
    "        if pagingText:\n",
    "            url = baseUrl + pagingText.get('href')\n",
    "    \n",
    "    resultsDf = pd.DataFrame(tableRows, columns=columnHeader)\n",
    "    find = re.compile(r\"^(\\n*).*\")\n",
    "    resultsDf['Team'] = resultsDf['Team'].apply(lambda x: re.search(find,x).group())\n",
    "    resultsDf = resultsDf.sort_values(by=['Team']).reset_index(drop=True)\n",
    "    return resultsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting team stats, calls getStats()\n",
    "def getTeamStats(url,side,categ,season,cols):\n",
    "    allCols = ['Team','weekType']+cols\n",
    "    seasonTypes = [\"PRE\",\"REG\",\"POST\"]\n",
    "    df = None\n",
    "    for st in seasonTypes:\n",
    "        teamPayload = {\"stats\":\"/stats\",\"subject\":\"team-stats\",\n",
    "               \"category\":side,\n",
    "               \"statisticCategory\":categ,\n",
    "               \"season\":season,\n",
    "               \"seasonType\":st,\n",
    "               \"list\":\"all\"}\n",
    "        tempDf = getStats(baseUrl,teamPayload)\n",
    "        tempDf['weekType']=st\n",
    "        tempDf = tempDf[allCols] \n",
    "        \n",
    "        # change raw stats to ordering\n",
    "        for i in cols:\n",
    "            colName = i + '(o)'\n",
    "            temp = pd.to_numeric(tempDf[i])\n",
    "            tempDf[colName] = temp\n",
    "            tempDf = tempDf.sort_values(by=colName).reset_index(drop=True)\n",
    "            tempDf[colName] = range(len(tempDf.index),0,-1)\n",
    "            temp = tempDf[colName].astype(str)\n",
    "            tempDf[colName] = temp\n",
    "            \n",
    "        df = pd.concat([df,tempDf])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://www.nfl.com/stats/team-stats/offense/passing/2019/pre/all\n",
      "url: https://www.nfl.com/stats/team-stats/offense/passing/2019/reg/all\n",
      "url: https://www.nfl.com/stats/team-stats/offense/passing/2019/post/all\n",
      "url: https://www.nfl.com/stats/team-stats/offense/rushing/2019/pre/all\n",
      "url: https://www.nfl.com/stats/team-stats/offense/rushing/2019/reg/all\n",
      "url: https://www.nfl.com/stats/team-stats/offense/rushing/2019/post/all\n",
      "url: https://www.nfl.com/stats/team-stats/defense/passing/2019/pre/all\n",
      "url: https://www.nfl.com/stats/team-stats/defense/passing/2019/reg/all\n",
      "url: https://www.nfl.com/stats/team-stats/defense/passing/2019/post/all\n",
      "url: https://www.nfl.com/stats/team-stats/defense/rushing/2019/pre/all\n",
      "url: https://www.nfl.com/stats/team-stats/defense/rushing/2019/reg/all\n",
      "url: https://www.nfl.com/stats/team-stats/defense/rushing/2019/post/all\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# specific stats desired\n",
    "poStats = ['Pass Yds','Yds/Att','Cmp %','TD','INT']\n",
    "roStats = ['Rush Yds','YPC','TD','Rush FUM']\n",
    "pdStats = ['Yds','Yds/Att','Cmp %','TD','INT']\n",
    "rdStats = ['Rush Yds','YPC','TD','Rush FUM']\n",
    "\n",
    "# function calls to get team stats\n",
    "teamPODf = getTeamStats(baseUrl,\"offense\",\"passing\",\"2019\",poStats)\n",
    "teamRODf = getTeamStats(baseUrl,\"offense\",\"rushing\",\"2019\",roStats)\n",
    "teamPDDf = getTeamStats(baseUrl,\"defense\",\"passing\",\"2019\",pdStats)\n",
    "teamRDDf = getTeamStats(baseUrl,\"defense\",\"rushing\",\"2019\",rdStats)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data frames to json files for copying to server\n",
    "dfs = [teamPODf,teamRODf,teamPDDf,teamRDDf]\n",
    "for i in range(len(dfs)):\n",
    "    with open(\"teamStat\"+str(i),\"w\") as outfile:\n",
    "        outfile.write(dfs[i].to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function for getting NFL schedule from nfl.com\n",
    "# def getMatchups(url,payload):\n",
    "#     for key in payload:\n",
    "#         if payload[key]:\n",
    "#             url += payload[key]\n",
    "#             url += '/'\n",
    "\n",
    "#     soup = BeautifulSoup(response.text,'html.parser')\n",
    "#     matchups = []\n",
    "#     columnHeader = ['matchupId', 'team1', 'team2', 'team1Score','team2Score','weekType','weekNum']\n",
    "#     season = soup.find_all('select', {\"class\":\"d3-o-dropdown\"})[1].find_all(\"option\")\n",
    "#     seasonWeeks = []\n",
    "#     for week in season:\n",
    "#         seasonWeeks.append(week.get(\"value\"))\n",
    "#     for week in seasonWeeks:\n",
    "#         time.sleep(2)\n",
    "#         url = baseUrl + week\n",
    "#         response = requests.get(url)\n",
    "#         print(url)\n",
    "#         soup = BeautifulSoup(response.text,'html.parser')\n",
    "#         weekName = week.rsplit('/', 2)[-2]\n",
    "#         weekType = re.findall(\"[a-zA-Z]+\", weekName)[0]\n",
    "#         weekNum = re.findall(r'\\d+', weekName)[0]\n",
    "#         games = soup.find_all('a', {\"class\": \"nfl-c-matchup-strip__game\"})\n",
    "#         index = 0\n",
    "#         for game in games:\n",
    "#             gameSoup = game.find_all('span', {\"class\":\"nfl-c-matchup-strip__team-abbreviation\"})\n",
    "#             matchup = []\n",
    "#             matchup.append(str(index))\n",
    "#             for team in gameSoup:\n",
    "#                 matchup.append(re.sub(r'[^A-Za-z]', '', team.get_text()))\n",
    "#             scoreSoup = game.find_all('div', {'class':\"nfl-c-matchup-strip__team-score\"})\n",
    "#             if scoreSoup:\n",
    "#                 for team in scoreSoup:\n",
    "#                     matchup.append(team.get_text())\n",
    "#             else:\n",
    "#                 matchup.append(\"\")\n",
    "#                 matchup.append(\"\")\n",
    "#             matchup.append(weekType)\n",
    "#             matchup.append(weekNum)\n",
    "#             matchups.append(matchup)\n",
    "#             index += 1\n",
    "#     matchupsDf = pd.DataFrame(matchups,columns=columnHeader)\n",
    "#     return matchupsDf\n",
    "\n",
    "\n",
    "# function for getting NFL schedule from espn.com\n",
    "def getMatchups(baseUrl,payload):\n",
    "    # get url to get array of weeks\n",
    "    url = baseUrl\n",
    "    for key in payload:\n",
    "        if payload[key]:\n",
    "            url += payload[key]\n",
    "            url += '/'\n",
    "    response = requests.get(url,timeout=(30, 27))\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    matchups = []\n",
    "    columnHeader = ['matchupId', 'team1', 'team2', 'team1Score','team2Score','weekType','weekNum','year']\n",
    "    season = soup.find_all('ul', {\"class\":\"dropdown-menu med\"})[1].find_all('li')\n",
    "    \n",
    "    # seasonWeeks is the array of weeks\n",
    "    seasonWeeks = []\n",
    "    for week in season:\n",
    "        seasonWeeks.append(week.find('a').get('href'))\n",
    "    \n",
    "    # iterate through weeks\n",
    "    for week in seasonWeeks:\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # load the matchups for the week\n",
    "        url = baseUrl + week\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text,'html.parser')\n",
    "        \n",
    "        # figure out the week type\n",
    "        if 'seasontype' in week:\n",
    "            if week.rsplit('/',2)[-1] == '1':\n",
    "                weekType = 'PRE'\n",
    "            else:\n",
    "                weekType = 'POST'\n",
    "        else:\n",
    "            weekType = 'REG'\n",
    "            \n",
    "        # find the year from the dropdown menu \n",
    "        year = soup.find_all('button', {\"class\":\"button-filter med dropdown-toggle\"})[1].text\n",
    "        \n",
    "        # find the week number \n",
    "        weekNum = soup.find_all('button', {\"class\":\"button-filter med dropdown-toggle\"})[2].text\n",
    "        if weekNum == 'Pro Bowl': continue\n",
    "        postType = {'Wild Card':'1','Divisional Round':'2','Conference Championship':'3','Super Bowl':'4'}\n",
    "        if weekType == 'POST':\n",
    "            weekNum = postType[weekNum]\n",
    "        else:\n",
    "            weekNum = re.findall(r'\\d+',weekNum)\n",
    "            if len(weekNum)==0: weekNum = '0'\n",
    "            else: weekNum = weekNum[0]\n",
    "        \n",
    "        # get list of all matchups for the week\n",
    "        games = []\n",
    "        for i in soup.find_all('div',{'class':'responsive-table-wrap'}):\n",
    "            if len(i.find_all('tbody')) > 0:\n",
    "                games.extend(i.find_all('tbody')[0].find_all('tr'))\n",
    "        index = 0\n",
    "        \n",
    "        # iterate through every game\n",
    "        for game in games:\n",
    "            # not a game row\n",
    "            if len(game.find_all('td')) < 5:\n",
    "                continue\n",
    "            matchup = [str(index)]\n",
    "            # check if game hasn't happened\n",
    "            live = len(game.find_all('td',{'class':'live'}))>0\n",
    "            timed = len(game.find_all('td',{'data-behavior':'date_time'}))>0\n",
    "            canceled = game.find_all('td')[2].text == 'Canceled'\n",
    "            tbd = game.find_all('td')[2].text == 'TBD'\n",
    "            postponed = game.find_all('td')[2].text == 'Postponed'\n",
    "\n",
    "            if live or timed or canceled or tbd or postponed:\n",
    "                team1 = game.find_all('td')[0].find_all('abbr')[0].text\n",
    "                team2 = game.find_all('td')[1].find_all('abbr')[0].text\n",
    "                matchup.extend([team1,team2])\n",
    "                matchup.extend(['-','-'])\n",
    "            else:\n",
    "                home = game.find_all('td')[1].find_all('abbr')[0].text\n",
    "                text = re.findall(r'\\w+',game.find_all('td')[2].find_all('a')[0].text)\n",
    "                if home == text[0]:\n",
    "                    text = [text[2],text[0],text[3],text[1]]\n",
    "                else:\n",
    "                    text = [text[0],text[2],text[1],text[3]]\n",
    "                matchup.extend(text)\n",
    "            matchup.extend([weekType,weekNum,year])\n",
    "            index += 1\n",
    "            matchups.append(matchup)\n",
    "    matchupsDf = pd.DataFrame(matchups,columns=columnHeader)\n",
    "    return matchupsDf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015', 'PRE', '0']\n",
      "['2015', 'PRE', '1']\n",
      "['2015', 'PRE', '2']\n",
      "['2015', 'PRE', '3']\n",
      "['2015', 'PRE', '4']\n",
      "['2015', 'REG', '1']\n",
      "['2015', 'REG', '2']\n",
      "['2015', 'REG', '3']\n",
      "['2015', 'REG', '4']\n",
      "['2015', 'REG', '5']\n",
      "['2015', 'REG', '6']\n",
      "['2015', 'REG', '7']\n",
      "['2015', 'REG', '8']\n",
      "['2015', 'REG', '9']\n",
      "['2015', 'REG', '10']\n",
      "['2015', 'REG', '11']\n",
      "['2015', 'REG', '12']\n",
      "['2015', 'REG', '13']\n",
      "['2015', 'REG', '14']\n",
      "['2015', 'REG', '15']\n",
      "['2015', 'REG', '16']\n",
      "['2015', 'REG', '17']\n",
      "['2015', 'POST', '1']\n",
      "['2015', 'POST', '2']\n",
      "['2015', 'POST', '3']\n",
      "['2015', 'POST', '4']\n",
      "['2016', 'PRE', '0']\n",
      "['2016', 'PRE', '1']\n",
      "['2016', 'PRE', '2']\n",
      "['2016', 'PRE', '3']\n",
      "['2016', 'PRE', '4']\n",
      "['2016', 'REG', '1']\n",
      "['2016', 'REG', '2']\n",
      "['2016', 'REG', '3']\n",
      "['2016', 'REG', '4']\n",
      "['2016', 'REG', '5']\n",
      "['2016', 'REG', '6']\n",
      "['2016', 'REG', '7']\n",
      "['2016', 'REG', '8']\n",
      "['2016', 'REG', '9']\n",
      "['2016', 'REG', '10']\n",
      "['2016', 'REG', '11']\n",
      "['2016', 'REG', '12']\n",
      "['2016', 'REG', '13']\n",
      "['2016', 'REG', '14']\n",
      "['2016', 'REG', '15']\n",
      "['2016', 'REG', '16']\n",
      "['2016', 'REG', '17']\n",
      "['2016', 'POST', '1']\n",
      "['2016', 'POST', '2']\n",
      "['2016', 'POST', '3']\n",
      "['2016', 'POST', '4']\n",
      "['2017', 'PRE', '0']\n",
      "['2017', 'PRE', '1']\n",
      "['2017', 'PRE', '2']\n",
      "['2017', 'PRE', '3']\n",
      "['2017', 'PRE', '4']\n",
      "['2017', 'REG', '1']\n",
      "['2017', 'REG', '2']\n",
      "['2017', 'REG', '3']\n",
      "['2017', 'REG', '4']\n",
      "['2017', 'REG', '5']\n",
      "['2017', 'REG', '6']\n",
      "['2017', 'REG', '7']\n",
      "['2017', 'REG', '8']\n",
      "['2017', 'REG', '9']\n",
      "['2017', 'REG', '10']\n",
      "['2017', 'REG', '11']\n",
      "['2017', 'REG', '12']\n",
      "['2017', 'REG', '13']\n",
      "['2017', 'REG', '14']\n",
      "['2017', 'REG', '15']\n",
      "['2017', 'REG', '16']\n",
      "['2017', 'REG', '17']\n",
      "['2017', 'POST', '1']\n",
      "['2017', 'POST', '2']\n",
      "['2017', 'POST', '3']\n",
      "['2017', 'POST', '4']\n",
      "['2018', 'PRE', '0']\n",
      "['2018', 'PRE', '1']\n",
      "['2018', 'PRE', '2']\n",
      "['2018', 'PRE', '3']\n",
      "['2018', 'PRE', '4']\n",
      "['2018', 'REG', '1']\n",
      "['2018', 'REG', '2']\n",
      "['2018', 'REG', '3']\n",
      "['2018', 'REG', '4']\n",
      "['2018', 'REG', '5']\n",
      "['2018', 'REG', '6']\n",
      "['2018', 'REG', '7']\n",
      "['2018', 'REG', '8']\n",
      "['2018', 'REG', '9']\n",
      "['2018', 'REG', '10']\n",
      "['2018', 'REG', '11']\n",
      "['2018', 'REG', '12']\n",
      "['2018', 'REG', '13']\n",
      "['2018', 'REG', '14']\n",
      "['2018', 'REG', '15']\n",
      "['2018', 'REG', '16']\n",
      "['2018', 'REG', '17']\n",
      "['2018', 'POST', '1']\n",
      "['2018', 'POST', '2']\n",
      "['2018', 'POST', '3']\n",
      "['2018', 'POST', '4']\n",
      "['2019', 'PRE', '0']\n",
      "['2019', 'PRE', '1']\n",
      "['2019', 'PRE', '2']\n",
      "['2019', 'PRE', '3']\n",
      "['2019', 'PRE', '4']\n",
      "['2019', 'REG', '1']\n",
      "['2019', 'REG', '2']\n",
      "['2019', 'REG', '3']\n",
      "['2019', 'REG', '4']\n",
      "['2019', 'REG', '5']\n",
      "['2019', 'REG', '6']\n",
      "['2019', 'REG', '7']\n",
      "['2019', 'REG', '8']\n",
      "['2019', 'REG', '9']\n",
      "['2019', 'REG', '10']\n",
      "['2019', 'REG', '11']\n",
      "['2019', 'REG', '12']\n",
      "['2019', 'REG', '13']\n",
      "['2019', 'REG', '14']\n",
      "['2019', 'REG', '15']\n",
      "['2019', 'REG', '16']\n",
      "['2019', 'REG', '17']\n",
      "['2019', 'POST', '1']\n",
      "['2019', 'POST', '2']\n",
      "['2019', 'POST', '3']\n",
      "['2019', 'POST', '4']\n",
      "['2020', 'PRE', '0']\n",
      "['2020', 'PRE', '1']\n",
      "['2020', 'PRE', '2']\n",
      "['2020', 'PRE', '3']\n",
      "['2020', 'PRE', '4']\n",
      "['2020', 'REG', '1']\n",
      "['2020', 'REG', '2']\n",
      "['2020', 'REG', '3']\n",
      "['2020', 'REG', '4']\n",
      "['2020', 'REG', '5']\n",
      "['2020', 'REG', '6']\n",
      "['2020', 'REG', '7']\n",
      "['2020', 'REG', '8']\n",
      "['2020', 'REG', '9']\n",
      "['2020', 'REG', '10']\n",
      "['2020', 'REG', '11']\n",
      "['2020', 'REG', '12']\n",
      "['2020', 'REG', '13']\n",
      "['2020', 'REG', '14']\n",
      "['2020', 'REG', '15']\n",
      "['2020', 'REG', '16']\n",
      "['2020', 'REG', '17']\n",
      "['2020', 'POST', '1']\n",
      "['2020', 'POST', '2']\n",
      "['2020', 'POST', '3']\n",
      "['2020', 'POST', '4']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchupId</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>team1Score</th>\n",
       "      <th>team2Score</th>\n",
       "      <th>weekType</th>\n",
       "      <th>weekNum</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MIN</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>PRE</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NYJ</td>\n",
       "      <td>DET</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>PRE</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>NE</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>PRE</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>BAL</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>PRE</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>MIA</td>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>PRE</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>POST</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>3</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>POST</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>POST</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>POST</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>POST</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1995 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    matchupId team1 team2 team1Score team2Score weekType weekNum  year\n",
       "0           0   PIT   MIN          3         14      PRE       0  2015\n",
       "1           0   NYJ   DET          3         23      PRE       1  2015\n",
       "2           1    GB    NE         22         11      PRE       1  2015\n",
       "3           2    NO   BAL         27         30      PRE       1  2015\n",
       "4           3   MIA   CHI         10         27      PRE       1  2015\n",
       "..        ...   ...   ...        ...        ...      ...     ...   ...\n",
       "329         2   TBD   TBD          -          -     POST       2  2020\n",
       "330         3   TBD   TBD          -          -     POST       2  2020\n",
       "331         0   TBD   TBD          -          -     POST       3  2020\n",
       "332         1   TBD   TBD          -          -     POST       3  2020\n",
       "333         0   TBD   TBD          -          -     POST       4  2020\n",
       "\n",
       "[1995 rows x 8 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function call for getting 2015-2020 seasons' schedules\n",
    "espnUrl = 'https://www.espn.com'\n",
    "schedulePayload = {\"sport\":\"/nfl\",\n",
    "                   \"type\":\"schedule\",\n",
    "                  \"underscore\":\"_\",\n",
    "                  \"year\":\"year\",\n",
    "                  \"yearNum\":\"2015\"}\n",
    "df2 = getMatchups(espnUrl,schedulePayload)\n",
    "for i in range(2016,2021):\n",
    "    schedulePayload['yearNum']=str(i)\n",
    "    df2 = df2.append(getMatchups(espnUrl,schedulePayload))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send schedule data frame to json file\n",
    "matchupsJson = df2.to_json(orient='records')\n",
    "\n",
    "with open(\"matchups.json\",\"w\") as outfile:\n",
    "    outfile.write(matchupsJson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to name different sections of the season\n",
    "weekTypeD = {\"PRE\":\"Pre-Season\", \"REG\":\"Regular Season\", \"POST\": \"Post-Season\"}\n",
    "\n",
    "# function to get the different weeks of the 2019 schedule\n",
    "def getWeeks(url,payload):\n",
    "    for key in payload:\n",
    "        if payload[key]:\n",
    "            url += payload[key]\n",
    "            url += '/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    columnHeader = ['weekType','weekNum','weekTypeF','weekF']\n",
    "    matchups = []\n",
    "    season = soup.find_all('select', {\"class\":\"d3-o-dropdown\"})[1].find_all(\"option\")\n",
    "    seasonWeeks = []\n",
    "    for week in season:\n",
    "        seasonWeeks.append(week.get(\"value\"))\n",
    "    for week in seasonWeeks:\n",
    "        url = baseUrl + week\n",
    "        weekName = week.rsplit('/', 2)[-2]\n",
    "        weekType = re.findall(\"[a-zA-Z]+\", weekName)[0]\n",
    "        weekNum = re.findall(r'\\d+', weekName)[0]\n",
    "        if weekType in weekTypeD.keys():\n",
    "            weekTypeF = weekTypeD[weekType]\n",
    "            weekF = weekTypeF + \" Week \" + weekNum\n",
    "            matchup = []\n",
    "            matchup.append(weekType)\n",
    "            matchup.append(weekNum)\n",
    "            matchup.append(weekTypeF)\n",
    "            matchup.append(weekF)\n",
    "            matchups.append(matchup)\n",
    "    weeksDf = pd.DataFrame(matchups,columns=columnHeader)\n",
    "    return weeksDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function call to get weeks and send to json file\n",
    "schedulePayload = {\"type\":\"/schedules\",\n",
    "                  \"season\":\"2018\",\n",
    "                  \"seasonType\":\"REG\"}\n",
    "df3 = getWeeks(baseUrl,schedulePayload)\n",
    "df3\n",
    "weeksJson = df3.to_json(orient='records')\n",
    "\n",
    "with open(\"weeks.json\",\"w\") as outfile:\n",
    "    outfile.write(weeksJson)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
